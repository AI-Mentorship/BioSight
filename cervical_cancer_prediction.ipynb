{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Create validation/test datasets***",
   "id": "30ec5c5389fe9e0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T05:14:48.741311Z",
     "start_time": "2025-10-08T05:14:48.738548Z"
    }
   },
   "cell_type": "code",
   "source": "import os, random, shutil",
   "id": "c1455968dbb74d00",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-09T06:04:43.705896Z",
     "start_time": "2025-10-09T06:04:43.686104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Copy the original data into test, train, and validate folders\n",
    "\n",
    "path_datasets = './datasets/original_data'\n",
    "train_dataset = './datasets/train'\n",
    "test_dataset = './datasets/test'\n",
    "validate_dataset = './datasets/validate'\n",
    "\n",
    "split= 0.7\n",
    "\n",
    "data_dirs = [\n",
    "    d for d in os.listdir(path_datasets)\n",
    "    if d.startswith('cervix') and os.path.isdir(os.path.join(path_datasets, d))\n",
    "]\n",
    "\n",
    "for cervix_ds in data_dirs:\n",
    "    # Check to see if files have already been copied\n",
    "    if os.listdir(os.path.join(train_dataset, cervix_ds)):\n",
    "        break\n",
    "\n",
    "    path_cervix_ds = os.path.join(path_datasets, cervix_ds)\n",
    "    files = [\n",
    "        f for f in os.listdir(path_cervix_ds)\n",
    "        if os.path.isfile(os.path.join(path_cervix_ds, f))\n",
    "    ]\n",
    "\n",
    "    num_sample = int(len(files) * split)\n",
    "    training_files = random.sample(files, num_sample)\n",
    "\n",
    "    for source_file in training_files:\n",
    "        source_file_path = os.path.join(path_cervix_ds, source_file)\n",
    "        destination_dir = os.path.join(train_dataset, cervix_ds)\n",
    "\n",
    "        if not os.path.exists(destination_dir):\n",
    "            os.makedirs(destination_dir)\n",
    "\n",
    "        shutil.copy2(source_file_path, destination_dir)\n",
    "\n",
    "    files = [\n",
    "        f for f in os.listdir(path_cervix_ds)\n",
    "        if f not in training_files\n",
    "    ]\n",
    "\n",
    "    num_sample = int(len(files) * 0.5)\n",
    "    testing_files = random.sample(files, num_sample)\n",
    "\n",
    "    for source_file in testing_files:\n",
    "        source_file_path = os.path.join(path_cervix_ds, source_file)\n",
    "        destination_dir = os.path.join(test_dataset, cervix_ds)\n",
    "\n",
    "        if not os.path.exists(destination_dir):\n",
    "            os.makedirs(destination_dir)\n",
    "\n",
    "        shutil.copy2(source_file_path, destination_dir)\n",
    "\n",
    "    validation_files = [\n",
    "        f for f in os.listdir(path_cervix_ds)\n",
    "        if f not in training_files and f not in testing_files\n",
    "    ]\n",
    "\n",
    "    for source_file in validation_files:\n",
    "        source_file_path = os.path.join(path_cervix_ds, source_file)\n",
    "        destination_dir = os.path.join(validate_dataset, cervix_ds)\n",
    "\n",
    "        if not os.path.exists(destination_dir):\n",
    "            os.makedirs(destination_dir)\n",
    "\n",
    "        shutil.copy2(source_file_path, destination_dir)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Destroy all training, testing, and validation data\n",
    "\n",
    "shutil.rmtree(train_dataset)\n",
    "shutil.rmtree(test_dataset)\n",
    "shutil.rmtree(validate_dataset)\n",
    "\n",
    "os.makedirs(train_dataset)\n",
    "os.makedirs(test_dataset)\n",
    "os.makedirs(validate_dataset)"
   ],
   "id": "4c9120f3e360d969"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Preprocess and Label data***",
   "id": "5adaa863252b0545"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T06:08:26.899639Z",
     "start_time": "2025-10-08T06:08:23.084471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "id": "ad7ad1f8a40f5bc3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T05:30:04.876337Z",
     "start_time": "2025-10-09T05:29:31.146825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cancer_type = ['cervix_dyk', 'cervix_koc', 'cervix_mep', 'cervix_pab', 'cervix_sfi']\n",
    "\n",
    "train_dataset_paths = [\n",
    "    os.path.join(train_dataset, ct) for ct in cancer_type\n",
    "]\n",
    "\n",
    "test_dataset_paths = [\n",
    "    os.path.join(test_dataset, ct) for ct in cancer_type\n",
    "]\n",
    "\n",
    "validation_dataset_paths = [\n",
    "    os.path.join(validate_dataset, ct) for ct in cancer_type\n",
    "]\n",
    "\n",
    "# Training data before preprocessing\n",
    "i = 0\n",
    "data_bptr = []\n",
    "\n",
    "for train_dp in train_dataset_paths:\n",
    "    for img_file in os.listdir(train_dp):\n",
    "        img = cv2.imread(os.path.join(train_dp, img_file))\n",
    "        data_bptr.append((img, i))\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "# Test data before preprocessing\n",
    "i = 0\n",
    "data_bpt = []\n",
    "\n",
    "for test_dp in test_dataset_paths:\n",
    "    for img_file in os.listdir(test_dp):\n",
    "        img = cv2.imread(os.path.join(test_dp, img_file))\n",
    "        data_bpt.append((img,i))\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "# Validation data before preprocessing\n",
    "i = 0\n",
    "data_bpv = []\n",
    "\n",
    "for val_dp in validation_dataset_paths:\n",
    "    for img_file in os.listdir(val_dp):\n",
    "        img = cv2.imread(os.path.join(val_dp, img_file))\n",
    "        data_bpv.append((img,i))\n",
    "\n",
    "    i = i + 1"
   ],
   "id": "aaa2bb05c2d9326d",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T05:30:08.501698Z",
     "start_time": "2025-10-09T05:30:08.494757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Classes for training, test, and validation data. This is so that we can use useful features\n",
    "#   (e.g., batching, shuffling) and to easily apply transformations on data\n",
    "class CancerDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        elm = self.transform(self.data[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return elm, label"
   ],
   "id": "758e16738f8bc452",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T05:30:10.229386Z",
     "start_time": "2025-10-09T05:30:10.222238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessed data of Dataset type\n",
    "\n",
    "# Unpacking each pair of images and labels\n",
    "# [(img,label),...] --> ((img,...), (label,...)) --> (img,...) and (label,...)\n",
    "training_data = CancerDataset(*zip(*data_bptr))\n",
    "test_data = CancerDataset(*zip(*data_bpt))\n",
    "validation_data = CancerDataset(*zip(*data_bpv))"
   ],
   "id": "1cf5af6535e604cf",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Dataloaders***",
   "id": "589b2e09b700cde9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T05:30:14.431303Z",
     "start_time": "2025-10-09T05:30:13.514904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loads 8 training data randomly from training_data\n",
    "# batch_size of 8 is chosen since image size is 3x512x512 which will be computationally expensive and\n",
    "#   some GPUs wouldn't be able to handle that much load\n",
    "training_dataloader = DataLoader(training_data, batch_size=8, shuffle=True)\n",
    "\n",
    "# There's no need to shuffle the test and validation data\n",
    "test_dataloader = DataLoader(test_data, batch_size=8)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=8)"
   ],
   "id": "d516368166659bd6",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***CNN Model Building***",
   "id": "cc0dbc4df2b94d70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f"
   ],
   "id": "a83c4bb3126af1b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T02:23:18.715421Z",
     "start_time": "2025-10-09T02:23:18.329693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1st layer - in: RGB (3 channels), out: 32 channels\n",
    "        #   ---> 5th layer - in: 215 channels, out: 512 channels\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling and this halves the input size\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layer: output features connected to all input features\n",
    "        # Input features: 512*16*16 ---> Output features: 5\n",
    "        self.fc1 = nn.Linear(in_features=512*16*16, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pool after every convolution\n",
    "        x = self.pool(f.relu(self.conv1(x)))\n",
    "        x = self.pool(f.relu(self.conv2(x)))\n",
    "        x = self.pool(f.relu(self.conv3(x)))\n",
    "        x = self.pool(f.relu(self.conv4(x)))\n",
    "        x = self.pool(f.relu(self.conv5(x)))\n",
    "\n",
    "        # Flatten output\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = f.relu(self.fc3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "my_model = CNN()"
   ],
   "id": "dd3afb3d79b71136",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Importing Model***",
   "id": "a6d42b1baeb1cf11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T02:24:56.678990Z",
     "start_time": "2025-10-09T02:24:56.389003Z"
    }
   },
   "cell_type": "code",
   "source": "import torchvision.models as models",
   "id": "42b2b53a86152681",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T05:45:40.993894Z",
     "start_time": "2025-10-09T05:45:40.668457Z"
    }
   },
   "cell_type": "code",
   "source": "resnet50_cdt = models.resnet50()",
   "id": "c665ce715ab69b71",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Train Model***",
   "id": "8cfa44a067bf4867"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from tqdm import tqdm",
   "id": "4d62c21cab41c9fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T05:42:51.882321Z",
     "start_time": "2025-10-09T05:42:51.869635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loss function for multiclass classification\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# Standard adam optimizer with learning rate of 1e-4\n",
    "optimizer = torch.optim.Adam(resnet50_cdt.parameters(), lr=1e-4)\n",
    "#optimizer = torch.optim.Adam(my_model.parameters(), lr=1e-4)\n",
    "# Set device as gpu if it exists\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train(num_epochs, model_type):\n",
    "    model_type.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch [{}/{}]\".format(epoch + 1,num_epochs))\n",
    "\n",
    "        # Set model to training mode\n",
    "        model_type.train()\n",
    "        for batch_idx, (data, labels) in enumerate(tqdm(training_dataloader)):\n",
    "            print(\"Batch: {}\".format(batch_idx))\n",
    "\n",
    "            # If cuda exists, data will be moved to the GPU memory\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model_type(data)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_function(outputs, labels)\n",
    "            # Set gradient to 0 before backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            optimizer.step()"
   ],
   "id": "f6728555a9265480",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "train(EPOCHS, resnet50_cdt)\n",
    "#train(EPOCHS, my_model)"
   ],
   "id": "5cc7e83fc1443035"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Evaluate Model***",
   "id": "3bce70bf1f17c2b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from torchmetrics.classification import MulticlassPrecision, MulticlassRecall, MulticlassAccuracy",
   "id": "d68578f14e16d53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T06:03:53.210839Z",
     "start_time": "2025-10-09T06:03:53.201845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model_type):\n",
    "    # Set model to evaluation mode\n",
    "    model_type.eval()\n",
    "\n",
    "    # Precision: How many were positive (correctly identifying cancer type) out of all predicted positives\n",
    "    # Recall: How many were correctly positive out of all positives\n",
    "    # Accuracy: How many did the model correctly predict\n",
    "    precision_metric = MulticlassPrecision(num_classes=5)\n",
    "    recall_metric = MulticlassRecall(num_classes=5)\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=5)\n",
    "\n",
    "    # Disable gradient tracking\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model_type(inputs)\n",
    "\n",
    "            # Calculate precision, recall, and accuracy as we iterate through the test dataloader\n",
    "            precision_metric.update(outputs, labels)\n",
    "            recall_metric.update(outputs, labels)\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "\n",
    "    # Compute final precision, recall, and accuracy\n",
    "    precision = precision_metric.compute()\n",
    "    recall = recall_metric.compute()\n",
    "    accuracy = accuracy_metric.compute()\n",
    "    print(\"Precision: {}, Recall: {}, Accuracy: {}\".format(i + 1, precision, recall, accuracy))"
   ],
   "id": "f5eb4d68ea911878",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "evaluate(resnet50_cdt)\n",
    "#evaluate(my_model)"
   ],
   "id": "2e960c87db89749c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Saving Model***",
   "id": "d5085b71b34cf14a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(resnet50_cdt.state_dict(), \"./resnet50_cdt.pth\")",
   "id": "470755381a3a7c7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Loading Model***",
   "id": "9ba229b87e540399"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T06:15:56.887624Z",
     "start_time": "2025-10-09T06:15:56.576080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load resnet50 without weights\n",
    "test_model = models.resnet50(weights=None)\n",
    "# Load weights into the model\n",
    "test_model.load_state_dict(torch.load(\"./resnet50_cdt.pth\"))\n",
    "test_model.eval()"
   ],
   "id": "b9c67091309aaec5",
   "outputs": [],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
