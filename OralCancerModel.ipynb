{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = \"/content/kagglehub_data/obulisainaren/multi-cancer\"\n",
    "\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    shutil.rmtree(dataset_path)\n",
    "\n",
    "path = kagglehub.dataset_download(\"obulisainaren/multi-cancer\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "oral_cancer_dir = os.path.join(path, \"Multi Cancer\", \"Multi Cancer\", \"Oral Cancer\")\n",
    "\n",
    "oral_dataset = datasets.ImageFolder(root=oral_cancer_dir, transform=transform)\n",
    "print(oral_dataset.class_to_idx)\n",
    "\n",
    "\n",
    "oral_dataset = datasets.ImageFolder(root=oral_cancer_dir, transform=transform)\n",
    "\n",
    "\n",
    "oral_loader = DataLoader(oral_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(\"Classes:\", oral_dataset.classes)\n",
    "print(\"Number of images:\", len(oral_dataset))\n",
    "print(\"Class to index mapping:\", oral_dataset.class_to_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(oral_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    oral_dataset, [train_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa00860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OralCancerClassifier(nn.Module):\n",
    "  def __init__(self, num_classes=2):\n",
    "      super(OralCancerClassifier, self).__init__()\n",
    "      self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "      self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "      enet_out_size = 1280\n",
    "      self.classifier = nn.Linear(enet_out_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.features(x)\n",
    "      x = torch.flatten(x, 1)\n",
    "      output = self.classifier(x)\n",
    "      return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa08ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OralCancerClassifier(num_classes=2).to(device)\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aadae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce56def",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Test Accuracy: {100*correct/total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS Kernel",
   "language": "python",
   "name": "aispro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
